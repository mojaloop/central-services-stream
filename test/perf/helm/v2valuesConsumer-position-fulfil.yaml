# Default values for central-services-stream-perf.
# This is a YAML-formatted file.

# Declare global configurations
global:
  config:
    ## Pod scheduling preferences.
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ##
    affinity: {}

    ## Node labels for pod assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
    nodeSelector: {}

    ## Set toleration for scheduler
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    tolerations: {}

# Declare variables to be passed into your templates.

replicaCount: 1

## Pod scheduling preferences.
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: "node-role.mojaloop.io"
              operator: In
              values: [ "ml_api" ]

## Node labels for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
nodeSelector: {}

## Tolerations labels for pod assignment
## Allow the scheduling on tainted nodes (requires Kubernetes >= 1.6)
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations:
  - key: "node-role.mojaloop.io"
    operator: "Equal"
    value: "ml_api"
    effect: "NoSchedule"

image:
  repository: mojaloop/central-services-stream-perf
  tag: v0.2
  pullPolicy: Always
  command: "node src/index.js consume --batchSize 1 --api --produceToTopic notification_fulfil"
  env: {}

init:
  enabled: true
  kafka:
    name: wait-for-kafka
    repository: solsson/kafka
    tag: latest
    pullPolicy: Always
    command: "until ./bin/kafka-broker-api-versions.sh --bootstrap-server $kafka_host:$kafka_port; do echo waiting for Kafka; sleep 2; done;"
    env: {}
    ## Env example
    # env:
    #   envItem1:
    #     name: hello
    #     value: world

service:
  name: cssperf
  type: ClusterIP
  externalPort: 80
  internalPort: 6969

  annotations: {}

  # This allows one to point the service to an external backend. 
  # This is useful for local development where one wishes to hijack 
  # the communication from the service to the node layer and point
  # to a specific endpoint (IP, Port, etc).
  external:
    enabled: false
    # 10.0.2.2 is the magic IP for the host on virtualbox's network
    ip: 10.0.2.2
    ports:
      api: 
        name: cssperf
        externalPort: 3081

readinessProbe:
  enabled: true
  httpGet:
    path: /health
    port: 6969
  initialDelaySeconds: 30
  periodSeconds: 15

livenessProbe:
  enabled: true
  httpGet:
    path: /health
    port: 6969
  initialDelaySeconds: 30
  periodSeconds: 15

ingress:
  enabled: true
  # Used to create an Ingress record.
  hosts:
    api: central-services-stream-perf.local
  
  externalPath: /
  
  annotations:
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  
  tls:
    # Secrets must be manually created in the namespace.
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

## metric configuration for prometheus instrumentation
metrics:
  ## flag to enable/disable the metrics end-points
  enabled: true
  config:
    timeout: 5000
    prefix: css_perf_
    defaultLabels:
      serviceName: css-perf-consumer-position

config:
  ## Kafka Configuration
  # this can be set if the dependency chart for kafka is disabled. If 'kafka_host' is commented out, then the name of the dependency chart will be used.
  # kafka_host: '$release_name-kafka'
  kafka_host: 'cssk-kafka'
  kafka_port: 9092
  producer:
    host: '0.0.0.0'
    port: 6868
  consumer:
    host: '0.0.0.0'
    port: 6969
    batch_size_value: 10
  statistics:
    intervalMs: 1000
  topics: 'position_fulfil'

kafka:
  enabled: false
  nameOverride: kafka
  # ------------------------------------------------------------------------------
  # Kafka:
  # ------------------------------------------------------------------------------

  ## The StatefulSet installs 3 pods by default
  replicas: 5

  ## The kafka image repository
  image: "confluentinc/cp-kafka"

  ## The kafka image tag
  # imageTag: "5.0.1"

  ## Specify a imagePullPolicy
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  imagePullPolicy: "IfNotPresent"

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources: {}
    # limits:
    #   cpu: 200m
    #   memory: 1536Mi
    # requests:
  #   cpu: 100m
  #   memory: 1024Mi
  kafkaHeapOptions: "-Xmx1G -Xms1G"

  ## The StatefulSet Update Strategy which Kafka will use when changes are applied.
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  updateStrategy:
    type: "OnDelete"

  ## Start and stop pods in Parallel or OrderedReady (one-by-one.)  Note - Can not change after first release.
  ## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
  podManagementPolicy: OrderedReady

  ## If RBAC is enabled on the cluster, the Kafka init container needs a service account
  ## with permissisions sufficient to apply pod labels
  rbac:
    enabled: true

  ## The name of the storage class which the cluster should use.
  # storageClass: default

  ## The subpath within the Kafka container's PV where logs will be stored.
  ## This is combined with `persistence.mountPath`, to create, by default: /opt/kafka/data/logs
  logSubPath: "logs"

  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  # schedulerName:

  ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## By default we don't set affinity
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #         - matchExpressions:
  #             - key: "node-role.mojaloop.io"
  #               operator: In
  #               values: [ "broker" ]
  ## Alternatively, this typical example defines:
  ## antiAffinity (to keep Kafka pods on separate pods)
  ## and affinity (to encourage Kafka pods to be collocated with Zookeeper pods)
  # affinity:
  #   podAntiAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #     - labelSelector:
  #         matchExpressions:
  #         - key: app
  #           operator: In
  #           values:
  #           - kafka
  #       topologyKey: "kubernetes.io/hostname"
  #   podAffinity:
  #     preferredDuringSchedulingIgnoredDuringExecution:
  #      - weight: 50
  #        podAffinityTerm:
  #          labelSelector:
  #            matchExpressions:
  #            - key: app
  #              operator: In
  #              values:
  #                - zookeeper
  #          topologyKey: "kubernetes.io/hostname"

  # Tolerations for nodes that have taints on them.
  # Useful if you want to dedicate nodes to just run kafka
  # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  # tolerations:
  #   - key: "node-role.mojaloop.io"
  #     operator: "Equal"
  #     value: "broker"
  #     effect: "NoSchedule"

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}

  ## Readiness probe config.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  ##
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    successThreshold: 1
    failureThreshold: 3

  ## Period to wait for broker graceful shutdown (sigterm) before pod is killed (sigkill)
  ## ref: https://kubernetes-v1-4.github.io/docs/user-guide/production-pods/#lifecycle-hooks-and-termination-notice
  ## ref: https://kafka.apache.org/10/documentation.html#brokerconfigs controlled.shutdown.*
  terminationGracePeriodSeconds: 60

  # tolerations:
  # - key: "key"
  #   operator: "Equal"
  #   value: "value"
  #   effect: "NoSchedule"

  ## External access.
  ##
  external:
    enabled: false
    servicePort: 19092
    firstListenerPort: 31090
    domain: cluster.local
    init:
      image: "lwolf/kubectl_deployer"
      # imageTag: "0.4"
      imagePullPolicy: "IfNotPresent"

  ## set extra ENVs
  #   key: "value"
  envOverrides:
    kafka.log4j.root.loglevel: INFO
    kafka.log4j.loggers: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"

  ## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
  ## here in map format, as defined in the official docs.
  ## ref: https://kafka.apache.org/documentation/#brokerconfigs
  ##
  configurationOverrides:
    ## Configure these to match the number of Kafka nodes for HA
    "offsets.topic.replication.factor": 1
    "default.replication.factor": 1
    # "auto.leader.rebalance.enable": true
    # "auto.create.topics.enable": true
    # "controlled.shutdown.enable": true
    # "controlled.shutdown.max.retries": 100

    ## Options required for external access via NodePort
    ## ref:
    ## - http://kafka.apache.org/documentation/#security_configbroker
    ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
    ##
    ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
    # "advertised.listeners": |-
    #   EXTERNAL://kafka.cluster.local:$((31090 + ${KAFKA_BROKER_ID}))
    # "listener.security.protocol.map": |-
    #   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

  ## A collection of additional ports to expose on brokers (formatted as normal containerPort yaml)
  # Useful when the image exposes metrics (like prometheus, etc.) through a javaagent instead of a sidecar
  additionalPorts: {}

  ## Persistence configuration. Specify if and how to persist data to a persistent volume.
  ##
  persistence:
    enabled: false

    ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
    ## production servers this number should likely be much larger.
    ##
    size: "1Gi"

    ## The location within the Kafka container where the PV will mount its storage and Kafka will
    ## store its logs.
    ##
    mountPath: "/opt/kafka/data"

    ## Kafka data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass:

  jmx:
    ## Rules to apply to the Prometheus JMX Exporter.  Note while lots of stats have been cleaned and exposed,
    ## there are still more stats to clean up and expose, others will never get exposed.  They keep lots of duplicates
    ## that can be derived easily.  The configMap in this chart cleans up the metrics it exposes to be in a Prometheus
    ## format, eg topic, broker are labels and not part of metric name. Improvements are gladly accepted and encouraged.
    configMap:

      ## Allows disabling the default configmap, note a configMap is needed
      enabled: true

      ## Allows setting values to generate confimap
      ## To allow all metrics through (warning its crazy excessive) comment out below `overrideConfig` and set
      ## `whitelistObjectNames: []`
      overrideConfig: {}
        # jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi
        # lowercaseOutputName: true
        # lowercaseOutputLabelNames: true
        # ssl: false
      # rules:
      # - pattern: ".*"

      ## If you would like to supply your own ConfigMap for JMX metrics, supply the name of that
      ## ConfigMap as an `overrideName` here.
      overrideName: ""

    ## Port the jmx metrics are exposed in native jmx format, not in Prometheus format
    port: 5555

    ## JMX Whitelist Objects, can be set to control which JMX metrics are exposed.  Only whitelisted
    ## values will be exposed via JMX Exporter.  They must also be exposed via Rules.  To expose all metrics
    ## (warning its crazy excessive and they aren't formatted in a prometheus style) (1) `whitelistObjectNames: []`
    ## (2) commented out above `overrideConfig`.
    whitelistObjectNames:  # []
      - kafka.controller:*
      - kafka.server:*
      - java.lang:*
      - kafka.network:*
      - kafka.log:*

  ## Prometheus Exporters / Metrics
  ##
  prometheus:
    ## Prometheus JMX Exporter: exposes the majority of Kafkas metrics
    jmx:
      enabled: true

      ## The image to use for the metrics collector
      image: solsson/kafka-prometheus-jmx-exporter@sha256

      ## The image tag to use for the metrics collector
      imageTag: a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8

      ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
      interval: 10s

      ## Port jmx-exporter exposes Prometheus format metrics to scrape
      port: 5556

      resources: {}
        # limits:
        #   cpu: 200m
        #   memory: 1Gi
        # requests:
      #   cpu: 100m
      #   memory: 100Mi

    ## Prometheus Kafka Exporter: exposes complimentary metrics to JMX Exporter
    kafka:
      enabled: true

      ## The image to use for the metrics collector
      image: danielqsj/kafka-exporter

      ## The image tag to use for the metrics collector
      # imageTag: v1.0.1

      ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
      interval: 10s

      ## Port kafka-exporter exposes for Prometheus to scrape metrics
      port: 9308

      ## Resource limits
      resources: {}
      #      limits:
      #        cpu: 200m
      #        memory: 1Gi
      #      requests:
      #        cpu: 100m
      #        memory: 100Mi
      # affinity:
      #   nodeAffinity:
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #         - matchExpressions:
      #             - key: "node-role.mojaloop.io"
      #               operator: In
      #               values: [ "broker" ]
      #       # Tolerations for nodes that have taints on them.
      # Useful if you want to dedicate nodes to just run kafka
      # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
      # tolerations:
      #   - key: "node-role.mojaloop.io"
      #     operator: "Equal"
      #     value: "broker"
      #     effect: "NoSchedule"

    operator:
      ## Are you using Prometheus Operator?
      enabled: false

      serviceMonitor:
        # Namespace Prometheus is installed in
        namespace: monitoring

        ## Defaults to whats used if you follow CoreOS [Prometheus Install Instructions](https://github.com/coreos/prometheus-operator/tree/master/helm#tldr)
        ## [Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/prometheus/templates/prometheus.yaml#L65)
        ## [Kube Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/kube-prometheus/values.yaml#L298)
        selector:
          prometheus: kube-prometheus

  # ------------------------------------------------------------------------------
  # Zookeeper:
  # ------------------------------------------------------------------------------

  zookeeper:
    ## If true, install the Zookeeper chart alongside Kafka
    ## ref: https://github.com/kubernetes/charts/tree/master/incubator/zookeeper
    enabled: true

    ## ref: https://github.com/kubernetes/contrib/tree/master/statefulsets/zookeeper#stateful-set
    # Desired quantity of ZooKeeper pods. This should always be (1,3,5, or 7)
    replicaCount: 3

    ## Configure Zookeeper resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    resources: ~

    ## The JVM heap size to allocate to Zookeeper
    heap: "1G"

    persistence:
      enabled: false
      ## The amount of PV storage allocated to each Zookeeper pod in the statefulset
      # size: "2Gi"

    ## Specify a Zookeeper imagePullPolicy
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    imagePullPolicy: "IfNotPresent"

    ## If the Zookeeper Chart is disabled a URL and port are required to connect
    url: ""
    port: 2181

    ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## By default we don't set affinity
    # affinity:
    #   nodeAffinity:
    #     requiredDuringSchedulingIgnoredDuringExecution:
    #       nodeSelectorTerms:
    #         - matchExpressions:
    #             - key: "node-role.mojaloop.io"
    #               operator: In
    #               values: [ "broker" ]
    ## Alternatively, this typical example defines:
    ## antiAffinity (to keep Kafka pods on separate pods)
    ## and affinity (to encourage Kafka pods to be collocated with Zookeeper pods)
    # affinity:
    #   podAntiAffinity:
    #     requiredDuringSchedulingIgnoredDuringExecution:
    #     - labelSelector:
    #         matchExpressions:
    #         - key: app
    #           operator: In
    #           values:
    #           - kafka
    #       topologyKey: "kubernetes.io/hostname"
    #   podAffinity:
    #     preferredDuringSchedulingIgnoredDuringExecution:
    #      - weight: 50
    #        podAffinityTerm:
    #          labelSelector:
    #            matchExpressions:
    #            - key: app
    #              operator: In
    #              values:
    #                - zookeeper
    #          topologyKey: "kubernetes.io/hostname"

    # Tolerations for nodes that have taints on them.
    # Useful if you want to dedicate nodes to just run kafka
    # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    # tolerations:
    #   - key: "node-role.mojaloop.io"
    #     operator: "Equal"
    #     value: "broker"
    #     effect: "NoSchedule"
